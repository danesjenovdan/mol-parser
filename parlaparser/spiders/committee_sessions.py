from datetime import datetime

from parlaparser import settings

import scrapy
import re
import logging


class CommitteeSessionsSpider(scrapy.Spider):
    name = 'committee_sessions'
    custom_settings = {
        'ITEM_PIPELINES': {
            'parlaparser.pipelines.ParlaparserPipeline': 1
        },
        'CONCURRENT_REQUESTS': '1'
    }
    allowed_domains = ['ljubljana.si']
    base_url = 'https://www.ljubljana.si'
    start_urls = ['https://www.ljubljana.si/sl/mestni-svet/odbori-in-komisije/']

    def __init__(self, parse_name=None, parse_type=None, *args,**kwargs):
        super().__init__(*args, **kwargs)
        self.parse_name = parse_name
        self.parse_type = parse_type

    def parse(self, response):
        for li in response.css(".sub-navigation>li"):
            paragraph_title = li.css("h3::text").extract_first()
            for body_url in li.css("a::attr(href)").extract():
                yield scrapy.Request(
                    url=self.base_url + body_url,
                    callback=self.parse_sessions_url,
                    meta={'classification': paragraph_title}
                )

    def parse_sessions_url(self, response):
        body_sessions_url = response.css(".square-icons a::attr(href)").extract_first()
        body_name = response.css(".header-holder h1::text").extract_first()
        yield scrapy.Request(
            url=self.base_url + body_sessions_url,
            callback=self.parse_body,
            meta={
                'classification': response.meta["classification"],
                'body_name': body_name
            }
        )

    def parse_body(self, response):
        for li in reversed(response.css("#page-content .ul-table li")):
            date = li.css("div")[1].css('p::text').extract_first()
            date = datetime.strptime(date, '%d. %m. %Y')
            if date < settings.MANDATE_STARTIME:
                continue

            name = li.css("div")[0].css('a::text').extract_first()
            if self.parse_name:
                logging.warning(f'{self.parse_name} {self.name}')
                if name != self.parse_name:
                    continue


            time = li.css("div")[2].css('p::text').extract_first()
            session_url = li.css("div")[0].css('a::attr(href)').extract_first()
            print({
                    'date': date,
                    'time': time,
                    'classification': response.meta["classification"],
                    'body_name': response.meta["body_name"]
                })
            yield scrapy.Request(
                url=self.base_url + session_url,
                callback=self.parse_session,
                meta={
                    'date': date,
                    'time': time,
                    'classification': response.meta["classification"],
                    'body_name': response.meta["body_name"]
                })


    def parse_session(self, response):
        find_enumerating = r'\b(.)\)'
        find_range_enumerating = r'\b(.)\) do \b(.)\)'
        order = 1
        
        words_orders = ['a', 'b', 'c', 'č', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']
        session_name = response.css(".header-holder h1::text").extract_first()
        if self.parse_type in ['speeches', None]:
            docx_files = response.css(".inner .attached-files .docx")
            for docx_file in docx_files:
                if 'Magnetogramski zapis' in docx_file.css('::text').extract_first():
                    speeches_file_url = docx_file.css('a::attr(href)').extract_first()

                    yield {
                        'type': 'speeches',
                        'docx_url': f'{self.base_url}{speeches_file_url}',
                        'session_name': session_name,
                        'date': response.meta["date"],
                        'time': response.meta["time"],
                        'classification': response.meta["classification"],
                        'body_name': response.meta["body_name"]
                    }

        notes = []
        for link in response.css('.attached-files a'):
            notes.append({
                'text': link.css('::text').extract_first(),
                'url': link.css('::attr(href)').extract_first()
            })

        for li in response.css(".list-agenda>li"):
            links = None
            agenda_name_special = li.css('.file-list-header h3.file-list-open-h3::text').extract_first()
            agenda_name_plain = li.css('.file-list-header h3::text').extract_first()
            links = []
            for link in li.css('.file-list-item a'):
                links.append({
                    'title': link.css('::text').extract_first(),
                    'url': self.base_url + link.css('::attr(href)').extract_first()
                })

            if agenda_name_special:
                agenda_name = agenda_name_special
            else:
                agenda_name = agenda_name_plain

            data = {
                'type': 'committee-agenda-items',
                'notes': notes,
                'session_name': session_name,
                'agenda_name': f'{order}. {agenda_name}',
                'date': response.meta["date"],
                'time': response.meta["time"],
                'classification': response.meta["classification"],
                'body_name': response.meta["body_name"],
                'order': order,
                'links': links
            }
            order += 1
            yield data
        
